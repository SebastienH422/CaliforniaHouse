{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936194b3",
   "metadata": {},
   "source": [
    "# 0) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1798d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d188a24",
   "metadata": {},
   "source": [
    "# 1) Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64332c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\" \n",
    "    # lien vers le dossier de téléchargement\n",
    "    #\n",
    "HOUSING_PATH = \"datasets/housing\" # chemin vers le dossier où sont stockés les fichiers\n",
    "HOUSING_URL = DOWNLOAD_ROOT + HOUSING_PATH + \"/housing.tgz\" # lien de téléchargement\n",
    "\n",
    "def fetch_housing_data(housing_url = HOUSING_URL, housing_path = HOUSING_PATH): \n",
    "    if not os.path.isdir(housing_path): # Création du dossier housing_path Si non existence\n",
    "        os.makedirs(housing_path) \n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\") # Mise en mémoire du fichier tgz_path ?\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path) # Téléchargement du fichier tgz\n",
    "    housing_tgz = tarfile.open(tgz_path) # Mise en mémoire de l'archive tgz\n",
    "    housing_tgz.extractall(path=housing_path) # Décompression de l'archive dans housing_path\n",
    "    housing_tgz.close()\n",
    "\n",
    "#fetch_housing_data() # Téléchargement du fichier\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH, name = 'housing'):\n",
    "    csv_path = os.path.join(housing_path, name + \".csv\") # Mise en mémoire du fichier csv\n",
    "    return pd.read_csv(csv_path) # Création de l'objet panda <DataFrame>\n",
    "\n",
    "    # Chargement des données\n",
    "housing = load_housing_data() # <class 'pandas.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70327e3",
   "metadata": {},
   "source": [
    "# 2) Création des jeux de test et d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f7e68faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/tj2026g138127nm7gbw5ljb00000gn/T/ipykernel_33132/2532620972.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    # split.split() renvoie un générateur contenant les labels du jeu de donnée d'entrainement, et de celui de test\n",
    "    #\n",
    "    #      IN: X <array-like of shape> (Données d'entrainement)\n",
    "    #          y <array-like of shape> (Label utilisé pour la stratification; étiquette en supervisé)\n",
    "    #     OUT: train, test <tuple of np.ndarray> \n",
    "    #\n",
    "    strat_train_set = housing.loc[train_index] # <pd.DataFrame> (Jeu d'entrainement)\n",
    "    strat_test_set = housing.loc[test_index] # <pd.DataFrame> (Jeu de test)\n",
    "\n",
    "# Suppression du label\n",
    "for set in (strat_train_set, strat_test_set, housing): \n",
    "    set.drop([\"income_cat\"], axis=1, inplace=True)\n",
    "\n",
    "# Copie des données\n",
    "Train = strat_train_set#.drop('median_house_value', axis = 1) \n",
    "Train_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "Test = strat_test_set.drop('median_house_value', axis = 1) \n",
    "Test_labels = strat_test_set['median_house_value'].copy()\n",
    "\n",
    "# Liste des attributs\n",
    "num_attr = list(Train.drop(['ocean_proximity', 'median_house_value'], axis = 1, inplace = False).columns)\n",
    "cat_attr = ['ocean_proximity']\n",
    "added_attr = ['rooms_per_household', 'population_per_household', 'bedrooms_per_rooms']\n",
    "ocean_attr = Train['ocean_proximity'].value_counts().index.tolist()\n",
    "\n",
    "total_attr = pd.Index(num_attr + added_attr + ocean_attr + ['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170fe49",
   "metadata": {},
   "source": [
    "# 3) Transformateurs sur mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2c4421d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room = True): # Stock le paramètre. ni *args ni **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room \n",
    "    \n",
    "    def fit(self, X, y = None): # Renvoie self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None): # Renvoie X modifié\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix] \n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix] \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else: \n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, label_selected):\n",
    "        self.label_selected = label_selected  \n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): # Renvoie les données de X dont le label est sélectionné\n",
    "        return X[self.label_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4ec83",
   "metadata": {},
   "source": [
    "# 4) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fcc699f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([('select', DataFrameSelector(num_attr)),\n",
    "                     ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                     ('lab_add', CombinedAttributesAdder()),\n",
    "                     ('standardisation', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('select', DataFrameSelector(cat_attr)),\n",
    "                     ('OneHot', OneHotEncoder(categories = [ocean_attr], handle_unknown = 'ignore')),\n",
    "                     ('imputer', SimpleImputer(strategy = 'constant', fill_value = 0, copy = True))])\n",
    "\n",
    "house_value_pipe = Pipeline([('select', DataFrameSelector(['median_house_value'])),\n",
    "                             #('imputer', SimpleImputer(strategy = 'median')),\n",
    "                             #('standardisation', StandardScaler())\n",
    "                             ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = \n",
    "                            [('numeric', num_pipe),\n",
    "                            ('categor', cat_pipe),\n",
    "                            ('house_value', house_value_pipe)\n",
    "                            ])\n",
    "\n",
    "full_pipeline_predict = FeatureUnion(transformer_list = \n",
    "                            [('numeric', num_pipe),\n",
    "                            ('categoric', cat_pipe)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c922523",
   "metadata": {},
   "source": [
    "# 5) Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4fbe33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_prepared_scp = full_pipeline.fit_transform(Train) # <scipy.csr_matrix>\n",
    "Test_prepared_scp = full_pipeline_predict.fit_transform(Test) # <scipy.csr_matrix>\n",
    "\n",
    "Train_prepared = pd.DataFrame(Train_prepared_scp.todense(), columns = total_attr) \n",
    "X = Train_prepared.drop('median_house_value', axis = 1) # Données d'entrainement\n",
    "y = Train_prepared['median_house_value'].copy() # Etiquettes pour l'entrainement\n",
    "\n",
    "Test_prepared = pd.DataFrame(Test_prepared_scp.todense()) # Données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142137ff",
   "metadata": {},
   "source": [
    "# 6) Choix du modèle\n",
    "\n",
    "## a) Fonctions d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbc1cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(x, y, titre = 'un modèle', p = 2, aff = True):\n",
    "    if p == 0:\n",
    "        score = max(x - y)\n",
    "    else:\n",
    "        somme = 0\n",
    "        for i in range(len(x)):\n",
    "            somme += abs(x[i] - y[i]) ** p\n",
    "        score = (somme / len(x)) ** (1/p)\n",
    "    if aff: print('\\nScore pour', titre, ': ', score)\n",
    "    return score\n",
    "\n",
    "def crossValid(model, X, y, titre = 'un modèle', nbSplit = 10):\n",
    "    brut_scores = cross_val_score(model, X, y, \n",
    "                                scoring = 'neg_mean_squared_error', cv = nbSplit)\n",
    "    scores = np.sqrt(- brut_scores)  \n",
    "\n",
    "    print('\\n\\nMoyenne des scores pour {}: {}\\nEcart-type: {}\\n'.format(titre, scores.mean(), scores.std()))\n",
    "\n",
    "def crossValid(model, X, y, NBSPLITS = 10):\n",
    "\n",
    "    skfolds = StratifiedKFold(n_splits=NBSPLITS)\n",
    "    scoreRMSE = 0\n",
    "\n",
    "    for train_index, test_index in skfolds.split(X, y): \n",
    "        clone_clf = clone(model)\n",
    "        \n",
    "        X_folds = X.iloc[train_index]\n",
    "        y_folds = y.iloc[train_index]\n",
    "        \n",
    "        X_test = X.iloc[test_index] \n",
    "        y_test = y.iloc[test_index]\n",
    "        \n",
    "        clone_clf.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "        \n",
    "        y_pred = clone_clf.predict(X.iloc[test_index])\n",
    "        scoreRMSE += RMSE(y_pred, y.iloc[test_index])\n",
    "        \n",
    "    print(scoreRMSE / NBSPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af75fb",
   "metadata": {},
   "source": [
    "## b) Déclaration des modèles et entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5affcbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "forest_reg = RandomForestRegressor()\n",
    "svr_reg = SVR(kernel = 'poly', degree = 2, C = 100, epsilon = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e90a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score pour un modèle :  66975.77789893825\n",
      "425823.8036928534 500001.0\n",
      "294754.1003758279 162500.0\n",
      "244271.88797501213 204600.0\n",
      "194552.9929249805 159700.0\n",
      "264550.73373103497 184000.0\n",
      "220451.95071436686 151900.0\n",
      "157819.46463151128 104900.0\n",
      "371200.6556060973 500001.0\n",
      "287998.178559611 367400.0\n",
      "229402.0351829362 346500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lin_reg.fit(X, y)\n",
    "prediction = lin_reg.predict(Test_prepared)\n",
    "RMSE(x = prediction, y = np.array(Test_labels))\n",
    "for k in range(10):\n",
    "    print(prediction[k], list(Test_labels)[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275c52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prediction))\n",
    "print(type(np.array(Test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a33c557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score pour un modèle :  66975.77789893825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66975.77789893825"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(x = prediction, y = np.array(Test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5e846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
